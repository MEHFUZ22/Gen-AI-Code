{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UbfuTOdgQsE"
   },
   "source": [
    "#Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSj3UeKaaXEY",
    "outputId": "b3912630-8c72-47dd-da74-f8896aa96227"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9598049521446228}, {'label': 'NEGATIVE', 'score': 0.9994558691978455}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier=pipeline(\"sentiment-analysis\")\n",
    "\n",
    "review=[\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    "\n",
    "\n",
    "result=classifier(review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZZtJWTQvZ5f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CreL8HJIw7_o",
    "outputId": "2c486225-98c0-4510-d140-3a52b6e5bc2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.991393506526947}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier=pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "review=\"The film was kind of good but not very good\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result=classifier(review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1VQ1yDT3iIl",
    "outputId": "0f8dd98e-0e44-4136-bc19-b72720bb560e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.9913764595985413}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier=pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "review=\"I am good not that good\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result=classifier(review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsXBxZ4ZxDZi",
    "outputId": "93de86e3-6058-4394-94bb-db27efbb9538"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9598049521446228}, {'label': 'NEGATIVE', 'score': 0.9994558691978455}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier=pipeline(\"sentiment-analysis\")\n",
    "\n",
    "reviews=[\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    "\n",
    "\n",
    "results=classifier(reviews)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOBXaGIIzEFQ",
    "outputId": "1c3a517a-6cab-4aee-ec18-be00137d285b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Review : I've been waiting for a HuggingFace course my whole life. | POSITIVE | 0.9598049521446228\n",
      " Review : I hate this so much! | NEGATIVE | 0.9994558691978455\n"
     ]
    }
   ],
   "source": [
    "for review ,result in zip(reviews,results):\n",
    "  print(f\" Review : {review} | {result['label']} | {result['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPcS2o6NgXla"
   },
   "source": [
    "#Summarisation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbhUJVEOzk_K"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "output_text = summary[0]['summary_text']\n",
    "print(output_text)\n",
    "print(\"Token count:\", len(tokenizer.encode(output_text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMH4BtOGYzf0"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Artificial Intelligence (AI) has rapidly become an integral part of our daily\n",
    "lives. From voice assistants like Siri and Alexa to recommendation systems on\n",
    "platforms like Netflix and Amazon, AI is shaping how we interact with technology.\n",
    "It is no longer confined to the realm of science fiction but is now a practical tool\n",
    "that enhances efficiency and convenience.\n",
    "One of the key drivers of AI adoption is its ability to analyze vast amounts of data\n",
    "and make predictions or decisions faster than humans. In industries like\n",
    "healthcare, AI-powered systems are used to detect diseases such as cancer in\n",
    "their early stages, saving countless lives. Similarly, in the financial sector, AI\n",
    "algorithms help identify fraudulent transactions and streamline investment\n",
    "strategies.\n",
    "However, the rise of AI also raises ethical concerns. Issues such as data privacy,\n",
    "algorithmic bias, and job displacement are frequently debated. While AI can\n",
    "improve productivity, it also has the potential to replace human jobs, particularly\n",
    "in repetitive or manual tasks. This highlights the need for responsible AI\n",
    "development and robust regulations to ensure that technology benefits everyone.\n",
    "Despite these challenges, the potential of AI is immense. Researchers are\n",
    "constantly working on advancements in natural language processing, computer\n",
    "vision, and machine learning to make AI even more intelligent and adaptable. As\n",
    "technology continues to evolve, it is likely that AI will play an even greater role in\n",
    "shaping our future.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403,
     "referenced_widgets": [
      "56606e31e4a84b56a1b4d4e23e401a98",
      "9b4324aafa4748358dc9afbff5d96dbc",
      "41ba6e49c0084c9c9aff1ff13297ec2f",
      "5aa6e2dcec524f7d903d92a4f3948381",
      "48c30ddb888b4c61b234443a2373af3c",
      "d98199aca662452fbcb0201636249576",
      "ab2861d7e7ea43fdb9a6d69aeec0d532",
      "54c723c424e240bcab2942c3fb48bdca",
      "f44dd0c2f1c94b8bb97cede8d00beaaa",
      "a41db31100654cf1a16f2d55509dc855",
      "3cb667ad10214570b5b8f34a0ed1fd72",
      "af40383d229d414e8e120af087f51fe1",
      "9a7dcfad44d647ffae1576d3f23177f7",
      "5facde89ac074536927e50fc158cd66c",
      "8ca0fa13ff2f4dafa04f49e8a531b8d2",
      "80772da2050e403485a61a0de22270f3",
      "0480dfd97d2d4801b26a7e7c30b96c06",
      "198f9956e3dc409881ddcc4bf972db35",
      "77f98dd1d2c74ae0a9b5b7b82f08e0c0",
      "636a8c8fe3da47c0ae379392549cfb7e",
      "5b918ab1f15b4e58a6bd8d70eb6ac1a5",
      "60ad1ff9ffe24608b425e2a62f60c82c",
      "bfa7105cff7649289bec6854af3ba1c5",
      "49ec24782f314c51a732661688dd7cdd",
      "8690d97b8d5d4bf099830a70fbf40c5f",
      "f429985396944cd9afddf3babede5356",
      "db04006aadf94bc1a7ccf45b677ea683",
      "1559cdf6884643c5ba00cb634557d4c3",
      "178ef837aa6e4bec91e799318c3f2ce2",
      "16b3dae533a147a4b4452c542419f78b",
      "e9d97725fe1443e5945a2155ff40ae6e",
      "603c7138dd664af5a9e6900b8a9d654e",
      "d261bd06fc314edd9970dd459745ab77",
      "8932592b77284c63827230a9af69108a",
      "1feccf57b93e49919d9c5f0b13bb4455",
      "c566fa0cf1f34efab9f523c6abae8881",
      "a85ca68149db40c790b47b076e75e6be",
      "c3d7ce7c2854419fad2a386e8e880b35",
      "2e48bfd5114e42d9a6a313cbe6c94e91",
      "7d9b8ef0d35546e99cec0ea73d5ff27e",
      "693c555d38cd4706a230dedad01a2076",
      "14ea9230a3ef4161b983684ad24b561e",
      "2d6c2bc64d5a45e692d28681c473136e",
      "3c94b336e98b457b9274f9459c9e9954",
      "22329f2ef5874530962db3dd1a0ffbb1",
      "1b9c0cab16204c97ac59e698367b60d3",
      "7804e0339ca14ab08172f964b30e1785",
      "65679d5e6f954bdda73a99c609544d39",
      "2f657a68e2db4f25b349ddda242d14c1",
      "fdcbe1e3cbe44ce8adcac86b4eeb620a",
      "cf22e68b4eac4de9a6f42ccc2aad5e4d",
      "978cdac87c184bf685a74db1b9a30a58",
      "a5e545acac834ba5b98c8f21c7114116",
      "bcb17cf1cfa1469eac6c67f55a82318d",
      "a878ac08374b40ec9472ffde19f23f12",
      "61d9930e52f94a11aad609416953e29e",
      "592a105b45494a4bb4347cd39b1b9e89",
      "a9d27fc0e75e488894699f8c25048eef",
      "fe4c9902981945d6a50403fb481bc80d",
      "9e7c0d29c90445c3a7bc98790445ab9d",
      "d5a4115a5dcc4c6fa72e981334175586",
      "0a537b766ebb4bbfb5ec6b36108cc5fa",
      "3d6bec72e7594270b95dc9e402432d7b",
      "b7ec8dda242c42208e67cc8ffbcb41c5",
      "45ee47d2ec84439e93dd9d86315c8fee",
      "a1ff3a6afdab4f41816acb6795e41252"
     ]
    },
    "id": "7XiXchRaY1k0",
    "outputId": "c2d54aa3-a33e-448f-e4af-7d8acb0ee31a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56606e31e4a84b56a1b4d4e23e401a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af40383d229d414e8e120af087f51fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa7105cff7649289bec6854af3ba1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8932592b77284c63827230a9af69108a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22329f2ef5874530962db3dd1a0ffbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d9930e52f94a11aad609416953e29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Artificial Intelligence (AI) has rapidly become an integral part of our daily lives . From voice assistants like Siri and Alexa to recommendation systems on platforms like Netflix and Amazon, AI is shaping how we interact with technology . The rise of AI also raises ethical concerns over data privacy and job displacement .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer=pipeline(\"summarization\")\n",
    "summary=summarizer(text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gASII7xuZAEs",
    "outputId": "12ef6cf7-1219-402f-dac0-2fdb1f2389d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Artificial Intelligence (AI) has rapidly become an integral part of our daily lives . From voice assistants like Siri and Alexa to recommendation systems on platforms like Netflix and Amazon, AI is shaping how we interact with technology . The rise of AI also raises ethical concerns over data privacy and job displacement .\n"
     ]
    }
   ],
   "source": [
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1RhLSOwZ-A_"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Artificial Intelligence (AI) has rapidly become an integral part of our daily\n",
    "lives. From voice assistants like Siri and Alexa to recommendation systems on\n",
    "platforms like Netflix and Amazon, AI is shaping how we interact with technology.\n",
    "It is no longer confined to the realm of science fiction but is now a practical tool\n",
    "that enhances efficiency and convenience.\n",
    "One of the key drivers of AI adoption is its ability to analyze vast amounts of data\n",
    "and make predictions or decisions faster than humans. In industries like\n",
    "healthcare, AI-powered systems are used to detect diseases such as cancer in\n",
    "their early stages, saving countless lives. Similarly, in the financial sector, AI\n",
    "algorithms help identify fraudulent transactions and streamline investment\n",
    "strategies.\n",
    "However, the rise of AI also raises ethical concerns. Issues such as data privacy,\n",
    "algorithmic bias, and job displacement are frequently debated. While AI can\n",
    "improve productivity, it also has the potential to replace human jobs, particularly\n",
    "in repetitive or manual tasks. This highlights the need for responsible AI\n",
    "development and robust regulations to ensure that technology benefits everyone.\n",
    "Despite these challenges, the potential of AI is immense. Researchers are\n",
    "constantly working on advancements in natural language processing, computer\n",
    "vision, and machine learning to make AI even more intelligent and adaptable. As\n",
    "technology continues to evolve, it is likely that AI will play an even greater role in\n",
    "shaping our future.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "4f509f7b37b34758a58d9b0b410ef5c5",
      "4bfb3577284b4801aa6e64df6d6747d1",
      "fc143617ed7b434daa65f5215029875d",
      "9ae392f4036346769fca11a28ca4d838",
      "e5922613510f425fa03b0a71587ab5c8",
      "8c178c54a96444db9a846b00cdd54ab8",
      "11114e43b6534ff18fd1c59e750aca4e",
      "e358a77342e8440ea6654def3498371c",
      "973fcdeffc0f4928af8f5a0cb07cc9cd",
      "88c5d8de0b384e71b923a4b12d3cfc75",
      "120644aaeb4b4d8c81615334a2239151",
      "407b19ed7dd04b2584dda8984a7bfd2b",
      "2c9fb11b1f8c445788beaabc4c475f93",
      "b85752b2ccb64f17bdd1c97768be60f1",
      "276f623c2e8945a49c7b9d100671b318",
      "b6f86520b770423993ca28b0845815a5",
      "4f1fb56c45ce46b1977a82d80a1bca65",
      "4afb8aac555946ef8bb6f0b368c8a40d",
      "e6a49ebe454540cbb1a7807f90fe4fd0",
      "90a345ebe19a4739a949b789f30503b6",
      "c193f487fc124183bed789963b91ff4e",
      "a74ecca6124846a8bfac77422e8ee536",
      "42154fdb1a484dd7a0592dd1a4b199ec",
      "362c51e56161476697be76556739f912",
      "799fc742dc9c4012b36dca8fd186cff9",
      "12b0f047299c4be9a584c555b594af11",
      "f480d89f9abc429da74b34b1c02ec687",
      "9044c1d02001405d85df58ee658ff44c",
      "bba812e2ff864907a832f26d49e92a4c",
      "b2133429ac56420cab775f92d9eb3d25",
      "0aba6a5dba9c461a8471fa1b33dc9d88",
      "c477e08732de48a4bf0fc5788d67c022",
      "78a2496c043549b890055e16414baeb9",
      "1879adc55e3949dfa48316c58c35608a",
      "6027287a1e62430aa0637df690094f5d",
      "3df7e4aa5c624f3aa53d0c23b4c34ebe",
      "e42b7970827b4bd880c67bed8253e3aa",
      "be03b512587e4b2387add9fabc791712",
      "27ed69b8484141a6ae86e04e886c84fc",
      "44e70535988947638b8429d8748045bb",
      "8fd4a83abbc24b479c0e6099bc74dcb2",
      "1212bcd1808f42d0918f3b6bf9cb77a5",
      "b09d65fa4cc74a7fbe58f4a43318db58",
      "ea244e1722b2435bb7bf965bf05a6f0a",
      "0a1b377951e44d9e8ea523d61c55227a",
      "4ee6040e1d6e4ed99c8d100d5b6eb093",
      "ef3d513c930d4bf686629d3f2dcb65a0",
      "8d448b45c3054e4bb0f0fc4b32e3c6f8",
      "a8910adabe0f4eacbdc0717b42cf4d95",
      "ab327e5313a94b02a8186b93a02f8b99",
      "99089ee5b35a4f21870ed4af0e189ee4",
      "ba0da967cf844639bf2f4025ba27c674",
      "d65b5ebf151c4689bec4c94e0347336d",
      "fda55b6c9b74457e90b42160ecc6d828",
      "febb17c389934b04b1a6a2e69609dba4",
      "ad3e1a07e66f4d71befe3eec24dc4425",
      "64fb9038810040c4853d35624db92308",
      "b31757e947bc414099dd5668282e7b66",
      "4c30515a9983423bbc486a35afea529a",
      "2b5545159e4e46e487738c1c734d4517",
      "537016c1fe7e4d75b02b9801126de584",
      "888cdebdf1d34e1cb3bd7c820d4874cb",
      "033ab209037f45978887c6ca6c31b6d1",
      "625a29b08600453683ee016d8c3b949f",
      "7b8b30d9115c4e93a480f41adc30ff45",
      "c4482a25b1794163a09b8a92c7c056af"
     ]
    },
    "id": "zToY_YFGaZ0T",
    "outputId": "4419bab3-82a6-48b7-a33c-eb5b29f3d993"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f509f7b37b34758a58d9b0b410ef5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407b19ed7dd04b2584dda8984a7bfd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42154fdb1a484dd7a0592dd1a4b199ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1879adc55e3949dfa48316c58c35608a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1b377951e44d9e8ea523d61c55227a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e1a07e66f4d71befe3eec24dc4425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'AI is now a practical tool that enhances efficiency and convenience . it can analyze vast amounts of data and make predictions or decisions faster than humans . in industries like healthcare, AI-powered systems are used to detect diseases .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer=pipeline(task=\"summarization\",model=\"t5-small\",min_length=10,max_length=20)\n",
    "summary=summarizer(text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9K709qfa3Ww",
    "outputId": "09d26e48-bfc5-4f5a-aa92-705bc2f66e69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'AI is now a practical tool that enhances efficiency and convenience . it can analyze vast amounts of data and make predictions or decisions faster than humans . in industries like healthcare, AI-powered systems are used to detect diseases .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer=pipeline(task=\"summarization\",model=\"t5-small\",min_length=5,max_length=5)\n",
    "summary=summarizer(text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4VDlvJrcNqv"
   },
   "source": [
    "to know the tokenizer count or lenght of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6b-zMBpbCbj",
    "outputId": "c522eff5-fced-411e-bcc9-e85d6ead63b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is now a practical tool that enhances efficiency and convenience . it can analyze vast amounts of data and make predictions or decisions faster than humans . in industries like healthcare, AI-powered systems are used to detect diseases .\n",
      "Token count: 49\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "output_text = summary[0]['summary_text']\n",
    "print(output_text)\n",
    "print(\"Token count:\", len(tokenizer.encode(output_text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "e9e5c9f5ecc645eba01f94d036a7bb15",
      "9ff13d15f7f2452b91e64ea1b55513e5",
      "74d4a137ecc24da6b909772d2083e50e",
      "872879b402d4465e97a3fe283f701807",
      "e7c35535c2074ded8fffb3c2fd896ef2",
      "1064797a184342f59cbc522b6a5e56a3",
      "bd262ba5e4bb463381d50de0f3c1c880",
      "cfd3b60f2cd5434ba60cf26cd0645166",
      "ae5e138db1cc4d2481a2e7e0175da6f4",
      "db3534966ead45108ff400c24968e560",
      "e8b7d29ee33e4de6b99b77c79653a4b1",
      "4524988acaab43f797fe7d516b148c2d",
      "bbb27f175c9d43f3ad7eae3333794ca7",
      "cf08133db1d14d6bbe115a62ea1524ee",
      "b097b761ac9247be9ead63cf8012b4b5",
      "3fd21e1c86644b87858a352eb4a2ab91",
      "b3b2aa65bcc445e9979067858056d176",
      "9fd3c6071011417c9a9aa8662ac8cf22",
      "a761e3d86dd4480b81026c0441e35402",
      "bcdf7090361f4b0fba09875f627170a8",
      "7058e8510a994010bffec372da4867f7",
      "cab02dc4e02a41bc9140a63b60dc5e54",
      "ff4fe2284498449e9f7ca6b2889e5208",
      "44cd329fe75a43f685889a76df4fabb0",
      "bfdc138529a743e190d4899f64e7f0d1",
      "c40ed0dcae3342a0849fdfc69b7cc6a9",
      "d6303c4f2c934fe7b9c9e46df08e16ba",
      "2416144754dc430cb736bbb348e1d9f9",
      "a611392a1e1641629fd63cfea12a4c1e",
      "d381feebc0374a2dbde0e9042a1a0632",
      "41a0cee533d74137bf0876cf4e130ce4",
      "1af25ce812b746bab297db5717554d27",
      "800ef3795a6d4a9798e8fc22363651ec",
      "44c1b94cd64b4588a87450f9c5e9b552",
      "02c18ddda9f1491c94aadc4d80f047b9",
      "773ab17450b94ab597ab0939ee7a83a5",
      "f81393b053dc4ed79a8d9817dca3b10c",
      "06313274b48248c5818c21f6534d451b",
      "9327912c073d465ea157393f06a5a7f3",
      "805c47bcaccf4e7b806d548e440f0612",
      "128985372e6d4e5a8517310f9d408136",
      "763934a3ede24723bcb125543416eca8",
      "f0b612ec7cd341a5bdb419e7ba00030f",
      "87deb7d5ac2d406997be7e882989952e",
      "f9ff1b1285d04a05b011b652d062dcd5",
      "3cc51a369e404fafbabd422d283d8ce6",
      "2d77be5316ae4b8ca70224186df87595",
      "8e2380252c7847869b180ee911e98ec8",
      "0fef2163c0ea4b9896901da2f3c46dd5",
      "c27011981ebb4edb98a61263463ba4d1",
      "74e25cdcc4b742e586f206a0b7a9d8fd",
      "6b4e0228499947d8b8f07c426e7320ff",
      "10e66694689a4f858935dce2d2513a1d",
      "1f37b2e379b44279801c62fb157427ae",
      "3cf75421a25944a98b9f3c8f9b0c12cb",
      "4940b6466c63404eb7ae8738d30825b4",
      "5bdab0c9f6d24191a425641666cb2176",
      "4e968cf4af25457bad58cdfb82bfc721",
      "075997d2866342a8b4715dcb15d517c5",
      "b9007ccfb71442d9a6f6002590c87fde",
      "d77e84ea89b24c76b43058aaeb70c9a1",
      "c9d3d1f6d0f142b6a41656bf7dc7dcd5",
      "fe0acff4e7ca4d0c8a9f1a48cf24b192",
      "1debd89e157744eeb60d6d3a3795de26",
      "62794fbf8d5846dfa0b7e87f7061694a",
      "97f5a26e96b744dcbb15995c5bd9d785"
     ]
    },
    "id": "hl17obJRbrL0",
    "outputId": "f6c188a6-87b2-49b9-8d8d-1d4204cca4a7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e5c9f5ecc645eba01f94d036a7bb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4524988acaab43f797fe7d516b148c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4fe2284498449e9f7ca6b2889e5208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c1b94cd64b4588a87450f9c5e9b552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ff1b1285d04a05b011b652d062dcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4940b6466c63404eb7ae8738d30825b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) has rapidly become an integral part of our daily lives. From voice assistants like Siri and Alexa to recommendation systems on Netflix and Amazon, AI is shaping how we interact with technology. But the rise of AI also raises ethical concerns.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, min_length=30, max_length=130)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7REbUjUjdRCc",
    "outputId": "8aac5484-9b9f-4b28-fddc-7d830060512e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) has\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, min_length=10, max_length=10)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7NU02mhd6c4",
    "outputId": "927583ca-9640-4f68-eba8-df26b372305c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 406,290,432\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Count total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvUJC5othIdD"
   },
   "source": [
    "#Questions and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229,
     "referenced_widgets": [
      "3bc11e6d711a4685a6f8cf5e8c52e693",
      "ef92245744334687ad7e0f07d6147a72",
      "b7e96b73aef64b07afd2e5458ddeb396",
      "6936f9ee830d4be1a753d0912a297a90",
      "f187ac3358b74029b54dd48c5576c5bf",
      "1cebf3acf95248db9271be6f5cfc1bf8",
      "c86ef3601b314fc7ac210d938e57c008",
      "df1960e16a704f9b80589a034a015b67",
      "e53437e074e54852bcf71e8aa1487cc0",
      "73de422a9099439f9f08eae47137c944",
      "b1bec5f30c4649d0ae222a034b4c5509",
      "00eb3363c08543999d3766a007c08e4f",
      "d48ba89138e947289b369dfc8a5c431d",
      "ebca65e0ed284634a63fb17b278df971",
      "127bbe77128e4aac960e0f8e8b6a989d",
      "68e14c628192415f825f9604b1ff0475",
      "3d0a95f371794be68b608d96ab697809",
      "dd4872bacf1341a890709261ba039ef9",
      "c4088a99135d420488d0f00d6cd80bd1",
      "e5983e68a36c4778a48cff6df4fd41cb",
      "03a83d906e6342d5a3bb016472516f6d",
      "a49e88500a7a4f6488c3fe8956dc09af",
      "ccc40581fec845b7a29675783e851956",
      "908268edfd084ea88157aca3abb6343e",
      "0e98bb66eb6a4a028949afc1899d84ff",
      "c8a06604dcb9419992cf58ec768a08ce",
      "71ebd7975f324a4f99aa5eb9507083cc",
      "96739aa9127d47cf98be585c822efe74",
      "568151879bb640c2bddb2a1abecb24d7",
      "095cb529d83444d3b0319a10effaa58c",
      "f156631ce4974076aa77a321b52247b5",
      "5482ffb07c0f4c70a3da92ac7c4b8d69",
      "2da0f828e29e4992a7a3eadee358cb37",
      "5fb8f6d333ef46429f2c935fb149df02",
      "2b0444bb7792469b801cdf2a348e47ae",
      "7722449371524d9db72ec112b783f338",
      "1c0e64b0bae740e2af38e96d1306102c",
      "d561dabe71074d9194a31ee339f1a5e5",
      "b2b2322f83ad448c928f3fe64e337124",
      "3fed35dbc7124544b35c99cb70618428",
      "5037089ebfa44ad1b99e8aaad6ff541d",
      "bee99598734144c79753d167a1d12e26",
      "3e4217640b5f40a3b739a88bd6e59a66",
      "e99e668b97f841a7816106de1dd350e8",
      "161d641b017c4431a405428c7af84c3a",
      "92ecb3bf434d488f87b08ae5e99219da",
      "648c8639a2c047739b9b5d274303d40d",
      "12e799929be349e583b9585fa65192eb",
      "f21fd8b02a104f8cbd35f39cd31e6e68",
      "d1bf9a9263354f8797252c0d1d9485c3",
      "2406aa7b9257469a8c17bd3d2612b2b9",
      "19b04285ccbf421ea006bccd7863343d",
      "2a97e70cacee46be8774d17d9afd9058",
      "0cf7c61657d14578bf53ceb3b45abcca",
      "02a8c33bb3cf410cb7ccfa96b27b94b6"
     ]
    },
    "id": "CIAk_KfvfcW_",
    "outputId": "491c3b39-a2d1-4ff8-af23-114d65db69eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc11e6d711a4685a6f8cf5e8c52e693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eb3363c08543999d3766a007c08e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc40581fec845b7a29675783e851956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb8f6d333ef46429f2c935fb149df02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161d641b017c4431a405428c7af84c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "question_answering=pipeline(task=\"question-answering\")\n",
    "\n",
    "context=\"\"\"\n",
    "Name: Mehfuz Ur Rahman\n",
    "Role: Big Data Developer\n",
    "Phone: +91 9886746347\n",
    "Email: mehfuz0831@gmail.com\n",
    "LinkedIn: linkedin.com/in/mehfuzurrahman\n",
    "Location: Bangalore, India\n",
    "\n",
    "SUMMARY:\n",
    "Skilled Big Data Engineer with 3 years of proven experience in designing and implementing efficient ETL processes. Proficient in Python, SQL, PySpark, and cloud-based data platforms. Strong collaborator with cross-functional teams to deliver high-quality solutions.\n",
    "\n",
    "SKILLS:\n",
    "- Programming: Python, SQL, PySpark\n",
    "- Data & Technologies: Apache Spark, Databricks, Azure Cloud, Azure Data Lake, Azure Data Factory, Azure Synapse, Hive\n",
    "- Data Engineering: ETL, Data Modelling, Data Warehousing\n",
    "- Tools: Git, GitHub, CI/CD\n",
    "- Cloud: AWS Redshift, AWS S3\n",
    "- Others: Machine Learning, Data Structures\n",
    "\n",
    "EXPERIENCE:\n",
    "\n",
    "**Data Engineer**\n",
    "Tata Consultancy Services\n",
    "Bangalore | Oct 2021 – Sep 2024\n",
    "\n",
    "Key Responsibilities:\n",
    "- Designed and implemented data pipelines using Azure Databricks and ADF, reducing data processing time by 25%.\n",
    "- Applied data quality checks using SQL and PySpark, improving accuracy by 15%.\n",
    "- Tuned SQL queries to optimize data retrieval by 20%.\n",
    "- Enhanced logic in PySpark and SQL to handle 60% of inconsistent data, improving quality.\n",
    "- Automated the MDM outbound process for seamless data integration.\n",
    "- Collaborated with teams and clients, documented processes to ensure knowledge transfer.\n",
    "\n",
    "KEY ACHIEVEMENTS:\n",
    "- **TCS Higher Talent Award**: Received “Elevate Wings” badge out of 200,000 participants for exceptional performance and impact.\n",
    "- **TFactor Excellence**: Achieved a T-factor score of 2.99 (benchmark: 1.99), recognized for steep learning curve and high contributions.\n",
    "\n",
    "CERTIFICATIONS:\n",
    "1. Microsoft Certified Azure Data Engineer\n",
    "2. Masters Program in Data Science (Simplilearn + IBM)\n",
    "3. HackerRank – SQL Advanced\n",
    "4. Google Data Analytics Professional Certificate\n",
    "\n",
    "EDUCATION:\n",
    "Bachelor of Engineering – Electronics and Communication\n",
    "Visvesvaraya Technological University, Bangalore\n",
    "Aug 2017 – Aug 2021\n",
    "\n",
    "LANGUAGES:\n",
    "- English\n",
    "- Kannada\n",
    "- Hindi\n",
    "- Bengali\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsuDWUrkgjc9"
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWjUfYPLfgBx",
    "outputId": "fa7083a7-ffce-49bb-a5e2-92c858f779f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.42046213150024414, 'start': 825, 'end': 862, 'answer': 'Tata Consultancy Services  \\nBangalore'}\n"
     ]
    }
   ],
   "source": [
    "qs=\"tell me the company name in which I have worked?\"\n",
    "result=question_answering(question=qs,context=context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298,
     "referenced_widgets": [
      "72a5554b9466464a88c7330f793134a7",
      "a80e11715c2c4044ab772cf4d840a44a",
      "1e6592e07a1746db812e4f83d3ad2da3",
      "49b2fe530e4e469a802d8864ddc6b969",
      "9845be93946840618376724c860ad22b",
      "a15521015d234f1d86e6f21d0edf92d7",
      "f1d101c0d7e44e44be23cb073802f53c",
      "aa0a252a3f974a0dae939e249d90389f",
      "e7b0c15c7f90492b9a42c3452cee662d",
      "823c6bb22a854166ae3618bc7dfbd3e5",
      "1ebdc6cc5cdb44b0b646654032c8b951",
      "65b22146259f4b488f4deb6076a410e5",
      "b1063073d4b24ac88a12d21f380cffd5",
      "6e9ede5308be4d36b91b3dc1f4eec27c",
      "04183f31fa2a4b25a6dfd21edc925368",
      "5a4ecf917c324a6b8a19f4a658446c92",
      "714278a7a88340a5b34e20c59f4d3f74",
      "2870b50acd81478b96fd7f3f50509b08",
      "97706c6eb45c42209ab38a71b60a109d",
      "9fed2af3cf4943a88ebabff15664ef23",
      "31b7d08d329d4113a8a79c14800fa89d",
      "1be5a673f0b748f0938d80a6230a909d",
      "f697a7f0cac44c559fd4140360523049",
      "79e5825b8bf54aa4850c7b772306ab73",
      "44776450623849bc8fff911bc586dd0e",
      "5edd101150c64fcd922d0b1a98550bd0",
      "fe5f6b947823430f9cb0687e21bbf689",
      "0fb3c5d980b14d95b1f8090a77916e79",
      "ac20d5306d514053ae385f12710a0614",
      "64a99f8949704c7094a286ec4800c000",
      "0d3d22afa3f34003b63e4b433cdea42e",
      "a922c03045994e728391d1a95cda0527",
      "401b5e0741b64186a7bf4fd266972ea4",
      "f647e22da8b84834be4678303b6e5500",
      "e41d535b1d7948a4b65da373553b8939",
      "3e9e424f4da64354a4318ad038d3e424",
      "361bbf1644e1460981486e7d953634b1",
      "98ef25b926ec433b9b9a5b4d2b3d3a46",
      "a4b9feffa3a34391b523095380bea87a",
      "2f7a06fdc36641bfbd3764d88baec2b5",
      "faf9cbf7c0d448418c3d07ea2535407e",
      "627bdd61a20148f1aeaba4647034a44a",
      "4a5665425b3d4530bde09ed0d1a339d2",
      "350418e091dc406487da0085bc2201bd",
      "3a4dc6900f9f446a80cc47025937dfa4",
      "7d270721e6a742c7b95410e6afdde022",
      "b23e477422d5477eb7b20f236f81c0ca",
      "437d8455d0cd4731b383288d36ad6176",
      "fc8caa2eba774ffb9e243343d9e91886",
      "f69f73110ddc483e8d5e646007cdb15e",
      "aa7d54b817c9452689ffd4d8cebdb5de",
      "08410db2cf524a84b96cd51db5ab31ba",
      "deb765f0f6224975b188ed1b6fccd090",
      "e54f4741128741bfaaaa30ff951eee3d",
      "30781ec9be2345f78181b172be121a73",
      "e8550a0b2d0b4731b6dfc94474d35d35",
      "9b124281f622409f9d941ba7787e74da",
      "74aa7aad1c5e46f695b4bac09daa3d45",
      "1bf850a8a71c4919afbbbfdcb751b90e",
      "e797872a2d6d4c3884bdf7e78b5f4252",
      "adead786417a40838f46f447174d8643",
      "2bb1ee66e5634b95b96756a4f5e37cde",
      "93a643dd8d2d4040970db2c8942368a7",
      "c0e812d2f69c440e8af6799a85d7a848",
      "3a416e0c7abb4e44b38e7d8f940ba141",
      "70c44a6efb6044ccb093a997f4504f13"
     ]
    },
    "id": "xxm4EDoeiiWw",
    "outputId": "afba52ef-972d-419b-fda3-76a78ae8dfbf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a5554b9466464a88c7330f793134a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b22146259f4b488f4deb6076a410e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f697a7f0cac44c559fd4140360523049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f647e22da8b84834be4678303b6e5500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4dc6900f9f446a80cc47025937dfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8550a0b2d0b4731b6dfc94474d35d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Certified Azure Data Engineer\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(task=\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "qs=\"tell me the company name in which I have worked?\"\n",
    "\n",
    "result = qa(question=qs, context=context)\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhhFTejTjtWd"
   },
   "outputs": [],
   "source": [
    "context=\"\"\"\n",
    "Mehfuz Ur Rahman is a Big Data Developer based in Bangalore, India, with 3 years of experience specializing in designing and implementing efficient ETL processes. He is proficient in Python, SQL, PySpark, and various cloud platforms including Azure Databricks, Azure Data Factory, Azure Synapse, Azure Data Lake, as well as AWS services like Redshift and S3. His skills encompass Apache Spark, data modeling, data warehousing, CI/CD, and machine learning fundamentals.\n",
    "\n",
    "From October 2021 to September 2024, Mehfuz worked as a Data Engineer at Tata Consultancy Services, where he led the development of data pipelines that reduced processing time by 25%. He improved data accuracy by 15% through quality checks and optimized SQL queries to enhance data retrieval by 20%. Mehfuz also enhanced PySpark and SQL logic to handle inconsistent data efficiently and automated master data management outbound processes. He collaborated extensively with cross-functional teams and ensured thorough documentation for smooth knowledge transfer.\n",
    "\n",
    "Mehfuz received notable recognition including the TCS Higher Talent Award among 200,000 participants and achieved a T-factor score of 2.99, surpassing the high proficiency benchmark. His certifications include Microsoft Certified Azure Data Engineer, a Masters Program in Data Science from Simplilearn in collaboration with IBM, HackerRank SQL Advanced, and Google Data Analytics Professional Certificate.\n",
    "\n",
    "He holds a Bachelor of Engineering degree in Electronics and Communication from Visvesvaraya Technological University, Bangalore. Mehfuz is fluent in English, Kannada, Hindi, and Bengali.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSKtUDP7jYzR",
    "outputId": "3e37168c-4695-4d41-a1c8-a23736134621"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 years\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(task=\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "qs=\"total experience I have?\"\n",
    "result = qa(question=qs, context=context)\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efWMEZksjg5Q",
    "outputId": "2fed7b7c-34a0-4494-a2dc-fdea52735dc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(task=\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "def get_answer(question, context=None):\n",
    "    if context is None:\n",
    "        context = \"\"\"\n",
    "        Mehfuz Ur Rahman is a Big Data Developer based in Bangalore, India, with 3 years of experience specializing in designing and implementing efficient ETL processes. He is proficient in Python, SQL, PySpark, and various cloud platforms including Azure Databricks, Azure Data Factory, Azure Synapse, Azure Data Lake, as well as AWS services like Redshift and S3. His skills encompass Apache Spark, data modeling, data warehousing, CI/CD, and machine learning fundamentals.\n",
    "\n",
    "        From October 2021 to September 2024, Mehfuz worked as a Data Engineer at Tata Consultancy Services, where he led the development of data pipelines that reduced processing time by 25%. He improved data accuracy by 15% through quality checks and optimized SQL queries to enhance data retrieval by 20%. Mehfuz also enhanced PySpark and SQL logic to handle inconsistent data efficiently and automated master data management outbound processes. He collaborated extensively with cross-functional teams and ensured thorough documentation for smooth knowledge transfer.\n",
    "\n",
    "        Mehfuz received notable recognition including the TCS Higher Talent Award among 200,000 participants and achieved a T-factor score of 2.99, surpassing the high proficiency benchmark. His certifications include Microsoft Certified Azure Data Engineer, a Masters Program in Data Science from Simplilearn in collaboration with IBM, HackerRank SQL Advanced, and Google Data Analytics Professional Certificate.\n",
    "\n",
    "        He holds a Bachelor of Engineering degree in Electronics and Communication from Visvesvaraya Technological University, Bangalore. Mehfuz is fluent in English, Kannada, Hindi, and Bengali.\n",
    "        \"\"\"\n",
    "    result = qa(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JCpd_98l6Da",
    "outputId": "ad7afe1a-333e-4ae3-ce59-590a77f6cc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Certified Azure Data Engineer\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(get_answer(\"What are Mehfuz's achievements?\"))\n",
    "print(get_answer(\"How many years of experience does Mehfuz have?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FCaDf5NYl-n8",
    "outputId": "15b30aa6-b0b5-493d-a5cc-cb27d2f23d2d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'October 2021 to September 2024'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"tell me the period mehfuz worked in in tata consultancy service\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H--h7nSDRJLn"
   },
   "source": [
    "#Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244,
     "referenced_widgets": [
      "51337a4ac7e64db086b58547661bdb3d",
      "3b83f0bddb8a4b409d0ea05ec41bcb2a",
      "f9d325bbb4894504b701518f92ed1098",
      "6418092f5c57412d9c6bf07e8ef691b0",
      "f03ec0bfac814afb877fc9a066117bf0",
      "60fcdad7650f40fb9acda8abc0ff6773",
      "66052e80d9754d17a20aef21d3cdbc11",
      "0828cc80b1684573a0d52b94bf7208b1",
      "c785ca8f20b94a5188b30b7391131d74",
      "1451f859dd1240eb82668cff2402ee7a",
      "27f907e30f3e4081ae457ab9d839cdb5",
      "65170937f3d4400fa2cbcab7824ae279",
      "dd9263aefef5492e9540139711640dc6",
      "e05eee79031e4fc889d3c4823887e1af",
      "fd83edf7168f47c5956c72ae19a8577e",
      "50d3f4e922d847df8d144bba677a88c7",
      "bf28fc34f72e464583382d81db5610a8",
      "b3889fb82b8547f9a09b34e8c5a40f75",
      "240d4a7a30fa477a9171b1b2817feca9",
      "c50cd1deb81245fa8d364231b77735ef",
      "5cd97ac07fca4d7fab97301a8d28336a",
      "816d253f6b8b41939d12712ba1da291e",
      "63603561c5064c159a87d8f511a41ea9",
      "ed8dec9faa7642e1bebce1be46606690",
      "c6aae6dcdb074b7193e3e4061aa0fe5d",
      "ffb7051e9e1d4518882e521233e92253",
      "903e66ec272648a8b41f83f563b7c91a",
      "906f9334edbb4cbf99a4742c709ac6c4",
      "f6284f1edc0549669f6ffc88d6a70917",
      "382b64a008514fa588b3be5a6d4ce7c5",
      "5653d1b7a6914558a1f806950a6c64a8",
      "6715dd7e5c684774b066604eccf7eb3e",
      "ba0daf1d6bd549eca1a5bc54a55001b1",
      "34fe18b45a994fc38340fc7e91e4c0a2",
      "63beab88e6324b5d9a9cda914cb69126",
      "cf3e9213aadd490185a450c90a5aa3d0",
      "7e63f7c30cc34114925703be53eb5a78",
      "4d4122c7003b4027bae494926a05b5e1",
      "5c6fe72eb773454ca82feb9b3b2943a6",
      "3fbc88552e5e45a892159cec48eeb824",
      "e0083da1a64b45c486994bdc0fa10c10",
      "b0827155a1d84950b94e2a0080ab561c",
      "a4d687b50ae34acfbf743d50b828112b",
      "d406d1486a734784a7db48c5a7c4d62c",
      "52e24900d5224f94960eb1cc7be1bb86",
      "a718cfaef59549d8a15f0556d66dff36",
      "d3a723e02ae1413280ea9497b62bbc5e",
      "a1a3ae46b42a475481a22b0e6aa70dfe",
      "d121f1b9943140c783341e40c7f99ceb",
      "e692e666ef65489890b8c62af69a8732",
      "9a99bd572e4b457ca9d2caa107dcf096",
      "85d54739a35544d4af7e4ff6a771dea3",
      "8dceb882bf76422e94bd4295f83d1a62",
      "a51c10fc3e124e09ac1cdc5df0997962",
      "8292703a3e8f4dbe8e488192febbb320",
      "efb07b9c44d44775be35667f82f0ed46",
      "f9a94e669d5c4c17864ddbcea3d231b1",
      "887fa86832b148b3a44019b870dcb127",
      "bb3647dd9ae845d6b6ffb51a59c43244",
      "18b1b5520e5042fbbd9b69aff05cedc9",
      "9a46d331d4974ddfa65e084097190183",
      "74fe9fefbd6e4d7e9f4c85c81e6c249c",
      "fa77c5f1f6ff4b80947fb11870983d6f",
      "9e3f2afb843e4c408302e634cb75dfbc",
      "6a3848429d874af3ac6f75050157d175",
      "d667db44f2714ea38537ad27aabb4fb9"
     ]
    },
    "id": "NlHtsprsmJEv",
    "outputId": "5a799738-ba92-408f-bcc4-3d7a52d1ff7d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51337a4ac7e64db086b58547661bdb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65170937f3d4400fa2cbcab7824ae279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63603561c5064c159a87d8f511a41ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fe18b45a994fc38340fc7e91e4c0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e24900d5224f94960eb1cc7be1bb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb07b9c44d44775be35667f82f0ed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'mehfuz est bon homme'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "translator=pipeline(task=\"translation_en_to_fr\",model='t5-small')\n",
    "\n",
    "text='mehfuz is good guy'\n",
    "result=translator(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "c43ecd1c92644a2f9bd99d4a8d3c7d37",
      "8c6da5cb0f664e51b5df8a71cc631833",
      "074aae626ece4d4e8619cb3d400289a2",
      "1f385f514c2c4a87b0e48fb5a51d3be7",
      "68fc9cd503c44fe99f8fc6f28f9781b3",
      "633452c891f0479f8bbd2aac05f43e0a",
      "e350e46149e34fbfb6e320d0e76512f2",
      "929d2048d0c1480981a1219cc73ccfeb",
      "4d7ec33d8a544c19abf02d6211e76b72",
      "c0d7fea640c343548db02f1a93f62858",
      "085978a7183a419daf6bd2293c0b08ac",
      "0204be08488a4378b25aa90075c8fe08",
      "3c7c3917a1824b9e8deb8b72c9d23c81",
      "dd1eac37143f4908966aa22ee11eee99",
      "09ab772a9ff049ffac4280a22ae34b2b",
      "3a46586ea82d4c829aa069dbdb6fa7d8",
      "9067205dc3004d9cbad4c85a35c425bd",
      "1b5c7151157242eeaee5d0011881f5d0",
      "a9b03e38bec148c4b8b1d532100c58f3",
      "81bb6b9a1c31435480a90561f71d33be",
      "48f7733ef53e435894cdbe432321cf9e",
      "a933b0e949ba457cbcdf3295d6a3c092",
      "0794b5c351f4488c9b51258d257d5abf",
      "b8e7f83ce55b447fb35ac594bc9f9895",
      "114b878d21b343999ad508a2353b87d8",
      "707a9888e0d74349be05b5b7752b970f",
      "40357b9d144e4771bae60789a0931244",
      "e29b1a0314044f739a962df0cb8cad3a",
      "33335be0ae8441fea8f722c599c415c5",
      "db086c23cbf045c398d574af7a3754e8",
      "3bc14f7d3787407ea11f57b3bed2be3d",
      "cbf9b338ef4d44cc848fa6c3c112e78a",
      "e86ec65dfab644daa10222982d66340e",
      "c79623c00aac4024bd0e5ba36f316816",
      "a5d6e941ed364286880b05dd0645173b",
      "ab3e19ca60654d9ca372e5a44ab54e5e",
      "ca45c36943b0433ba7f3aa099960ff5d",
      "4a5e070fc57645d985400437caba11a7",
      "930f03b51eab44efb7eb95bf67403b9e",
      "8d9cc3cc3ef94a1ebe6e0ae72d56d479",
      "e532325bf0074bc8a9b075f4aef78226",
      "b10f0326376f4174ac076689d0c19c94",
      "5b1d2395fa454745b1820c056bdd2160",
      "c14a5f3f6a114b38a1cbea350849059f",
      "b3418dd101144feda1fcdd4e3b78049a",
      "7c056005642f446e81627d0f1519b45f",
      "6464722d58914500a1b2378918b5c689",
      "f32aee7b82894e659b37809103cf7887",
      "3508f0bb57e94e2c86a1c834774fc1c6",
      "d6fe8ed7e08f4f3aa4189f032f7046e3",
      "0d3859e9e9e2494eac0882fb1f7c67be",
      "d7a3413d60d0437ea8af3e5e1e4fcfbb",
      "afcc84e19394442d98c1bb698a1d2614",
      "a85583005b5e41e19850ff450f92ff81",
      "802afe3a459249e7b5909930d1c097bc"
     ]
    },
    "id": "vXo8Ah7ORiZi",
    "outputId": "ec9070ca-8127-4543-c7d1-d95843fe7ad8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43ecd1c92644a2f9bd99d4a8d3c7d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0204be08488a4378b25aa90075c8fe08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0794b5c351f4488c9b51258d257d5abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79623c00aac4024bd0e5ba36f316816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3418dd101144feda1fcdd4e3b78049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'mehfuz est un bon homme'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "translator=pipeline(task=\"translation_en_to_fr\",model='t5-base')\n",
    "\n",
    "text='mehfuz is good guy'\n",
    "result=translator(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0KmHDgQSBi3",
    "outputId": "45d4d83d-cbbb-4123-922c-7f817e5c564c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       13289424 kB\n",
      "MemFree:          873120 kB\n",
      "MemAvailable:    7887920 kB\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         108G   41G   67G  38% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm             5.8G  4.0K  5.8G   1% /dev/shm\n",
      "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n",
      "tmpfs           6.4G   20M  6.4G   1% /var/colab\n",
      "/dev/sda1        73G   42G   31G  58% /kaggle/input\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo | grep Mem\n",
    "!df -h  # check disk space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruK6i1H_bnBX"
   },
   "source": [
    "##Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321,
     "referenced_widgets": [
      "3b42526a036e49c2861bed0cb2835117",
      "40ff281aa3f240cd9c56492dee95d06e",
      "3d84863d8e2a41aebaaf9eaa5d0b86d4",
      "275f2d45a42b4c60ba30722d7a6aa23f",
      "76add3c365434ffdad5890a45e21ca1a",
      "83df0a03bed240799b49a4b351aa4c07",
      "9d8c450bd612492ca9de4e612edac934",
      "267eb930f70f474b97847c3c677bb68d",
      "b548347e28174137917730f92aa44589",
      "675f1676f4124c55818e9ad3a542bec3",
      "f12097a0b78e4c8c85f5ad6cda8e2e8f",
      "a0f1c28613044fb5a1be5156fd600e3c",
      "4902b14886884f26aeb2c7830c6dadd4",
      "a1e2916ea0494161806ed0e180ce5525",
      "f36dcc0847a44fa1a7e2a0b75006a2fe",
      "b4ebb628d4704e73abb5b18ef3060c0e",
      "ed84ff14ee9149dfbb2be2335a6b3afb",
      "70281b3edfb640cebd850f53a31532b4",
      "345b5bd1064c41979b301f85aa2196a0",
      "9f347c439cc64ad5b1e810160a7aa993",
      "a3618111a40e44348e696f5b3ed4e554",
      "1cd8d9db5400403d9cf23f53388b8016",
      "1f1b44af34b14b83b9d2252b77ab7029",
      "bd327f17e1ea44a69cfb404ad28d1392",
      "aace39103a064ce087ee5fdf1ffd3f23",
      "c4c851cb20c84f17a538483f69d41d1c",
      "8fd6ac8ff64841bcb4e44a4339d1bf86",
      "a2dfeda55f9f4e2587e291a9da0a8971",
      "05775cdddbb9404d922cc473b4b3b49d",
      "e7c4a3bbb2314645a82ce677f4463425",
      "1dc9328e88ec4f54a6b15dafe8699508",
      "97c5318b6c354fcc969a1b0f62c452b8",
      "4da0b83830d24cabbe4702ee94e1aade",
      "5e447bbe113048938fa2de8427a8360e",
      "c9f2753c46f74a30a3305117710fdcfb",
      "40a2fbf4cba54595a090369705f8fc75",
      "d276aa162ad1464382eed474d7c87798",
      "2b2fefedc8f847df98a4c2c2695aeacd",
      "bc8bc5effed441028316888ea97aff09",
      "6bec56d5a3774edb83ced8af437ab922",
      "10fe3a3e8c86428ca3b5e1fe90003553",
      "5d2f0990a1fa4e948ff1d901bed02055",
      "ab45c5632538484ea34affdc6f74e4bc",
      "468f4d4745cd4811bd4a2a3cc670d62d"
     ]
    },
    "id": "t5zdLKkTbmxA",
    "outputId": "ff0df6e9-76e4-43e3-8a17-e275a62a565e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b42526a036e49c2861bed0cb2835117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f1c28613044fb5a1be5156fd600e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1b44af34b14b83b9d2252b77ab7029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e447bbe113048938fa2de8427a8360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': np.float32(0.9994467), 'index': 1, 'word': 'El', 'start': 0, 'end': 2}, {'entity': 'I-PER', 'score': np.float32(0.99876237), 'index': 2, 'word': '##on', 'start': 2, 'end': 4}, {'entity': 'I-PER', 'score': np.float32(0.99889475), 'index': 3, 'word': 'Mu', 'start': 5, 'end': 7}, {'entity': 'I-PER', 'score': np.float32(0.9955519), 'index': 4, 'word': '##sk', 'start': 7, 'end': 9}, {'entity': 'I-ORG', 'score': np.float32(0.99919814), 'index': 6, 'word': 'Space', 'start': 18, 'end': 23}, {'entity': 'I-ORG', 'score': np.float32(0.99900395), 'index': 7, 'word': '##X', 'start': 23, 'end': 24}, {'entity': 'I-ORG', 'score': np.float32(0.9995678), 'index': 11, 'word': 'Te', 'start': 37, 'end': 39}, {'entity': 'I-ORG', 'score': np.float32(0.999033), 'index': 12, 'word': '##sla', 'start': 39, 'end': 42}, {'entity': 'I-ORG', 'score': np.float32(0.999501), 'index': 13, 'word': 'Motors', 'start': 43, 'end': 49}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "ner=pipeline(task='ner')\n",
    "\n",
    "text='Elon Musk founded SpaceX in 2002 and Tesla Motors in 2003'\n",
    "entities=ner(text)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425,
     "referenced_widgets": [
      "9f93d2c0776c49d4a7fc475f0c47268b",
      "7966b71e0f674a46befa0e74ba3ae633",
      "b70345f2ba6c4723b54ccae22edc85d7",
      "090c7c723ae34639be091f19c929dd22",
      "a4069b4ddbe148829db2fa0708ffb7fa",
      "263ae979a72b41179e72a7ae8a7130b3",
      "1b1d5abed2344ae48a83bd98748f2900",
      "33ddee8a4da942968ec192c9361d6983",
      "32cb3ba774dd410aa9942e1f2d41674d",
      "f10ad3112c0b4b1f8b2addd515bbfd4f",
      "46c5f98a34f74d7cba482f8a07939603",
      "fa8b01d5029d4dc985f355b96b8b8c4f",
      "065642c2e14f416aa7e6c3647aa001d4",
      "ee5fa8f813ec4ada9860d055068ca320",
      "748bb31db44e4b1d9e0e9152bf6c60a1",
      "962428effc7e4504910a9d75837b4201",
      "e0585b597fa0415aad149f487481401a",
      "9e0a8a8e18ef4b739fbe3834e6937d5c",
      "13f0fb0b2144485f9acb7a1d1975f977",
      "034ebb6b7797485ea053e6f6bf08b352",
      "4ae67d4ea4ca484cb2e4b3482f859565",
      "1ba912231d9d4ff89b69065b901f6fa9",
      "e5e10298b6204de59387accd84dc1240",
      "fcc9ea62bcce4b7f8057a77024796823",
      "6dcf0df5b185444b8775aa6fbec0f805",
      "0c7bb3832d2346c98046a96d96e7a2f9",
      "a7f2ae6bbe9b439b8891e85f52300d57",
      "0121684ee9c34352b36ea198bede51fe",
      "adb52ce1499c41f5b3e720f6e483bd43",
      "8772ef55200f44d0beecdf2ea311a650",
      "db9df26983a7491994ee43452aa6e017",
      "b73042ce2b774f51988f7f2e339c9f93",
      "db785ce77c754b74a95a9140e9d25d54",
      "5bcd4ac12087485a80e174fddd0d399e",
      "fb3b644b4bc14c7ca6e14879651a4e69",
      "089ab11156cb486b8688b857f8be94d6",
      "a274ee0488d445c193e7fda445d4eb78",
      "09639e52a8ac47e78f2965d07ce50b0e",
      "a1b814bb876b43e08307f2b3c33d5c44",
      "d89b944fb9a44dd4a5e4af243e93070f",
      "1d62aba1b2a3473d991494cc1f714699",
      "8c2a00c120be4b3e8217f635d9bfcde1",
      "a97ca4a8a31142ab9f3dbd139ad2ca9e",
      "33c3ee5807204de991620bd4bafd77d2"
     ]
    },
    "id": "k2sUx0CZcDGy",
    "outputId": "763ae07b-3ddd-4602-f063-4a06fe270878"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f93d2c0776c49d4a7fc475f0c47268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8b01d5029d4dc985f355b96b8b8c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e10298b6204de59387accd84dc1240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcd4ac12087485a80e174fddd0d399e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': np.float32(0.9981639), 'word': 'Elon Musk', 'start': 0, 'end': 9}, {'entity_group': 'ORG', 'score': np.float32(0.99910104), 'word': 'SpaceX', 'start': 18, 'end': 24}, {'entity_group': 'ORG', 'score': np.float32(0.99936724), 'word': 'Tesla Motors', 'start': 37, 'end': 49}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "ner=pipeline(task='ner',grouped_entities=True)\n",
    "\n",
    "text='Elon Musk founded SpaceX in 2002 and Tesla Motors in 2003'\n",
    "entities=ner(text)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgalKQvtNw_f",
    "outputId": "8df449c1-53d3-452e-fa8e-c03a397d94ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': np.float32(0.9981639), 'word': 'Elon Musk', 'start': 0, 'end': 9}, {'entity_group': 'ORG', 'score': np.float32(0.99910104), 'word': 'SpaceX', 'start': 18, 'end': 24}, {'entity_group': 'ORG', 'score': np.float32(0.99936724), 'word': 'Tesla Motors', 'start': 37, 'end': 49}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "ner=pipeline(task='ner',grouped_entities=True)\n",
    "\n",
    "text='Elon Musk founded SpaceX in 2002 and Tesla Motors in 2003'\n",
    "entities=ner(text)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djFDKtrvqupW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ux9QoXFq-Jk"
   },
   "source": [
    "#Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hugHVXHgq_Yb",
    "outputId": "4378f58a-bfbd-4a9d-9bb3-1565be77068d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.18057487905025482, 'token': 6768, 'token_str': 'delhi', 'sequence': 'delhi is the capital of india'}, {'score': 0.1614084541797638, 'token': 2009, 'token_str': 'it', 'sequence': 'it is the capital of india'}, {'score': 0.08124436438083649, 'token': 8955, 'token_str': 'mumbai', 'sequence': 'mumbai is the capital of india'}, {'score': 0.08072150498628616, 'token': 13624, 'token_str': 'hyderabad', 'sequence': 'hyderabad is the capital of india'}, {'score': 0.06982014328241348, 'token': 23571, 'token_str': 'lucknow', 'sequence': 'lucknow is the capital of india'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask=pipeline(task=\"fill-mask\",model=\"bert-base-uncased\")\n",
    "text=\"[MASK] is The capital of India \"\n",
    "predictions=fill_mask(text)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxPCTd7nrVEN",
    "outputId": "7de3fa06-e6c9-4c15-da7a-e3cb4b97a7fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7236712574958801, 'token': 1012, 'token_str': '.', 'sequence': 'capital of america is.'}, {'score': 0.14907433092594147, 'token': 1025, 'token_str': ';', 'sequence': 'capital of america is ;'}, {'score': 0.06741386651992798, 'token': 1064, 'token_str': '|', 'sequence': 'capital of america is |'}, {'score': 0.030373698100447655, 'token': 999, 'token_str': '!', 'sequence': 'capital of america is!'}, {'score': 0.028260309249162674, 'token': 1029, 'token_str': '?', 'sequence': 'capital of america is?'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask=pipeline(task=\"fill-mask\",model=\"bert-base-uncased\")\n",
    "text=\"Capital of America is [MASK] \"\n",
    "predictions=fill_mask(text)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ny_d7LIWsVzP",
    "outputId": "ce27ed54-05f2-4093-cd34-705486713031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.0764598548412323, 'token': 20260, 'token_str': ' toast', 'sequence': 'Capital of America is toast'}, {'score': 0.026086673140525818, 'token': 1367, 'token_str': ' closed', 'sequence': 'Capital of America is closed'}, {'score': 0.025735294446349144, 'token': 16921, 'token_str': ' shrinking', 'sequence': 'Capital of America is shrinking'}, {'score': 0.023722056299448013, 'token': 3172, 'token_str': ' closing', 'sequence': 'Capital of America is closing'}, {'score': 0.017050106078386307, 'token': 27588, 'token_str': ' crumbling', 'sequence': 'Capital of America is crumbling'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask=pipeline(task=\"fill-mask\")\n",
    "text=\"Capital of America is <mask>\"\n",
    "predictions=fill_mask(text)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSvpM8K0s3Sw"
   },
   "source": [
    "#Text Generation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMaiKw-t0O1F",
    "outputId": "eeaeebb2-8dfb-43ed-8446-5c7c2da23e95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'once upon a time there was foxes, leopards, and the like, that were to be found in the forests, far away from the great cities of India. The forest was a place of no more than a thousand acres, and was a place of immense beauty and of deep interest. The people, who had all their life toil in the forest, had scarcely seen any fox. Yet in the middle of the night, if one was at leisure, a man came to a place where there was a huge, square forest, and he asked if there was any fox there. \"Well,\" said the man, \"as much as you will admit, it is a fox.\" \"It is a fox!\" exclaimed the man, \"that is to say, a dog, that is to say, a dog-head, and that is to say, a fox-beast.\" \"I will not be able to tell you that a dog is a dog,\" said the man, \"and that you would love to know it. And you will find, by the way, that it is a fox-scout.\" \"That is not a dog-head, either,\" said the man, \"as a fox-hound-dog is a fox-hound-breeder.\" \"But you'}, {'generated_text': \"once upon a time there was foxing. There was a young lady who was a long-time member of the royal family and she was also a woman. She looked pretty, she was very kind and it was like she had been looking for something. I saw her and I was like, 'What did she say to me?' I said I did! That's when she said, 'I do not know what she said to me so I will not talk to you until I hear it.' And so she came out and she looked at me and she said, 'What did you say?' So I said, 'I told you she was a girl. I will tell you what I told you.' She said, 'Well, I have been looking for her since when she was a girl. She has been searching for me for a long time.' So I was like, 'You know what I really want to know, because I have been looking for her for a long time.' So I was like, 'Well that's it.' She said, 'I have to say I never expected you to be so kind to me.' So I said, 'Yes, it is. I really do.' And she said, 'So do I.' So I said, 'Well, I have been looking\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator=pipeline(task=\"text-generation\")\n",
    "\n",
    "prompt=\"once upon a time there was fox\"\n",
    "\n",
    "generated_text=generator(prompt,max_length=50,num_return_sequences=2)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO8b4lSWa-Ey"
   },
   "source": [
    "#Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hEex2vE2wsE",
    "outputId": "90a72e30-882e-44c6-d0b2-21afcdeccee4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 768])\n",
      "tensor([[[-0.0644,  0.3072, -0.2403,  ..., -0.2252,  0.4909,  0.3453],\n",
      "         [ 0.0946, -0.0482, -0.5109,  ..., -0.8580,  0.9796,  0.2480],\n",
      "         [ 0.1433,  0.4354,  0.0365,  ..., -1.1490, -0.4520, -0.8382],\n",
      "         ...,\n",
      "         [ 0.4254,  0.0395,  0.3553,  ..., -0.0688,  0.3166, -0.3482],\n",
      "         [-0.2445, -0.5005,  0.0497,  ...,  0.5193,  0.5687, -0.3280],\n",
      "         [ 0.7259,  0.2183, -0.0821,  ...,  0.2618, -0.5756, -0.3668]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "feature_extractor=pipeline(task=\"feature-extraction\",model=\"bert-base-uncased\")\n",
    "\n",
    "text=\"Mehfuz is very curious guy\"\n",
    "feature=feature_extractor(text,return_tensors=\"pt\") #pt->pytorch | tensor\n",
    "\n",
    "print(feature.shape)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyCGNkwJcKLN",
    "outputId": "a9f50409-9e75-429f-b0ff-f31c1c486e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 768])\n",
      "tensor([[[-0.2152,  0.1030, -0.2293,  ..., -0.3293,  0.6107,  0.4966],\n",
      "         [ 0.0065,  0.2570, -0.4677,  ..., -1.0981,  0.8092,  0.1457],\n",
      "         [ 0.0104,  0.5732,  0.2129,  ..., -1.1941, -0.6981, -0.7373],\n",
      "         ...,\n",
      "         [-0.0462, -0.0240,  0.7333,  ..., -0.0728,  0.1586, -0.6160],\n",
      "         [-0.0725, -0.1594,  0.3120,  ...,  0.4188,  0.0967, -0.6107],\n",
      "         [ 0.3023,  0.0615,  0.4857,  ...,  0.5289, -0.1642, -0.3487]],\n",
      "\n",
      "        [[ 0.1842,  0.4473, -0.0721,  ..., -0.2856,  0.5538,  0.2169],\n",
      "         [ 0.5064,  0.0792, -0.0768,  ..., -0.0598,  1.2614, -0.3738],\n",
      "         [ 0.8088,  0.6948,  0.7463,  ..., -0.0521,  0.5078, -0.0668],\n",
      "         ...,\n",
      "         [ 0.7548,  0.2545, -0.1094,  ...,  0.3407, -0.3656, -0.5227],\n",
      "         [ 0.9808,  0.2626,  0.2601,  ...,  0.3280, -0.5331, -0.4088],\n",
      "         [ 0.6813,  0.2631,  0.1256,  ...,  0.2393,  0.1491, -0.0665]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = [\n",
    "    \"Mehfuz is very curious guy.\",\n",
    "    \"He loves learning new things every day.\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get last hidden states (features)\n",
    "features = outputs.last_hidden_state\n",
    "print(features.shape)  # (batch_size, seq_len, hidden_size)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuIuLBhZ0C1H"
   },
   "source": [
    "#Zero Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "7318b9dc3c554821ac1b9b048752c11f",
      "c1b8256d4103411e8d0b967f0bb58097",
      "f750b1a3c7c44edcb43fca261004a589",
      "7b1cc83fddf342bdb4b7c4718fb59e33",
      "1d0f12cdc4ed4ed5aa65f2f20021577d",
      "8a48768d23e7492490a93eb4a11997ca",
      "ff6159a637d14b0887ada2c093f9d55f",
      "e74b01a7876b4187a216e13134c5537c",
      "0d7b178744644496942e3866d4833e5c",
      "b75670a8c8ca4e5c89b798c536e28509",
      "5e2a1140995f458fafffebb9afd7c697",
      "7adeaacab57d483e94c19d1e5012a77e",
      "a4ab8209ac3a484e82835a39dae9bd3f",
      "56a4f7a6f88e4595ab2bd9f33177d9e4",
      "22e60a8322b74c4a9967eed0354d34fc",
      "11a41d10b95f47bab02b5bb261a170a3",
      "6c2862b9b6384d6485b1ba2160cf681f",
      "3694e86a441f4b539a88ea5d6240c216",
      "f8a4dcb00ef94e32911f0a6efcdfe711",
      "7085b65d77b94080926137862cc8c0d8",
      "ae15e37042fb4ce69716f5cbcb16304d",
      "f86a8f146919484da0b5243893f0ef82",
      "12c1a5eed6e04633b4382f4d8d9f81ac",
      "d082ee9fa17e4d17b32d536afbaee54a",
      "7842c3ded7a444ea9da4ccf3cef883d5",
      "eb55edaf2cf54adc868732c849e24aa0",
      "c3a4976ab0ff45f6872b08de2b25a0bb",
      "a3c06ea8b99e4482bade56a4f6e8cbab",
      "b222ade67fe84d9bbf012f78e733cfef",
      "32fcf6a1441c49cfbff542a7d914512d",
      "8a8c3359f25c467ab34a6b3f5d6a84bb",
      "714022aa1b0c424581740e5915739d1a",
      "34f016e18bb4490692d2b60a539c69f7",
      "fdb869202e5c44bcb68f5d7d37b8709a",
      "41e73d66d5ab41ce807c2d24d999ae64",
      "67e073150ae5482492eb40ca8219f9dd",
      "fe8234148fb1408cb81a660dcf747f7a",
      "274b905075e94784bbf9c53123138a3c",
      "2a7ba49abe2c4225a1f87ae43be7ea0a",
      "35c3337013614e30868b7107490982be",
      "582489b211714e1594b1ea5feab79983",
      "cc74845bafa0467da892f4d611a30de0",
      "d3f8e5aa2924436ca9c024998fb97e15",
      "cd296adb606c4e5f850966a047a2005d",
      "74923c8360ca45a3a853eb1524497fea",
      "bca20156ec68418ebbabe61c37ed2197",
      "ca3888a2ebac4a9ca1169b9e75e6514c",
      "60c22d3ab0af48e286d7d64f8741ea18",
      "2e86a7eca77840adb1e3209ae5c669d0",
      "2f1e228e78e046be8b4a688f783f443d",
      "78df52a10c4b424d95444dcf8227b78b",
      "eb808e1d44f04f4ba141016863b2142a",
      "4e1375a900494d2081695249c005609e",
      "8b4dfb50e2a647858620828b1d73b387",
      "2abe05ad2a7243d9ad45a8b2ca0d7fa1",
      "7b5d6ad0d5c34cb49f0cec2be84fee60",
      "929b5b34fd7f42e7a8e18917b91dff48",
      "79122e6782284c6daa0f8b37557d11a5",
      "d7db875e2490461caffc651a14a5bfc1",
      "28cd8af65b60464bad4714dc9ce03e98",
      "bab4a58c8d11434399ae5bef4c376c66",
      "1c8fcd13dd6f45329663d74a0b834666",
      "b06dd537aa4348dbb20dcc0ff3d7f245",
      "0682f19bbd2a47fb8f8bf04e1235f40e",
      "020abd12e8414056a8744fab0c5fa145",
      "4c8cc45c69dc49649fb2c9fed9f9a18c"
     ]
    },
    "id": "v5YtyxupdhbE",
    "outputId": "52fc4bb6-bfed-4179-d6b8-8e301f717e78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7318b9dc3c554821ac1b9b048752c11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adeaacab57d483e94c19d1e5012a77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c1a5eed6e04633b4382f4d8d9f81ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb869202e5c44bcb68f5d7d37b8709a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74923c8360ca45a3a853eb1524497fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5d6ad0d5c34cb49f0cec2be84fee60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'I have leno laptop which is very old now even the performance is not so good', 'labels': ['tech', 'sports', 'politics'], 'scores': [0.9480116367340088, 0.027083642780780792, 0.024904659017920494]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier=pipeline(\"zero-shot-classification\",model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "text=\"I have leno laptop which is very old now even the performance is not so good\"\n",
    "candidate_labels=[\"tech\",\"sports\",\"politics\"]\n",
    "\n",
    "\n",
    "result=classifier(text,candidate_labels=[\"tech\",\"sports\",\"politics\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5IKxmG50CgA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xn32rT3JjDm-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned notebook saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook C:/Users/Zufhe/Downloads/Transfomers_week3_01.ipynb to html\n",
      "[NbConvertApp] Writing 715268 bytes to C:\\Users\\Zufhe\\Downloads\\Transfomers_week3_01.html\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "# Change this to your notebook file name\n",
    "path = \"C:/Users/Zufhe/Downloads/Transfomers_week3_01.ipynb\"\n",
    "\n",
    "\n",
    "# Load notebook\n",
    "nb = nbformat.read(path, as_version=4)\n",
    "\n",
    "# Remove 'widgets' metadata if present\n",
    "if \"widgets\" in nb.metadata:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "# Save cleaned notebook\n",
    "nbformat.write(nb, path)\n",
    "print(\"Cleaned notebook saved successfully.\")\n",
    "\n",
    "# Convert to HTML\n",
    "!jupyter nbconvert --to html \"$path\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "faUhFpk9jEAH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterthemes in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyterthemes) (5.3.0)\n",
      "Requirement already satisfied: notebook>=5.6.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyterthemes) (6.4.12)\n",
      "Requirement already satisfied: ipython>=5.4.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyterthemes) (7.31.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyterthemes) (3.7.1)\n",
      "Requirement already satisfied: lesscpy>=0.11.2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyterthemes) (0.15.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (68.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (3.0.36)\n",
      "Requirement already satisfied: pygments in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (2.15.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.4.6)\n",
      "Requirement already satisfied: ply in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (5.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (3.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (25.1.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (8.1.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (5.7.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.5.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (1.5.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.25.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.14.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterthemes) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterthemes) (305.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=1.4.3->jupyterthemes) (3.11.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jupyter-client>=5.3.4->notebook>=5.6.0->jupyterthemes) (6.0.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.12.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (4.17.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.4.1->jupyterthemes) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->jupyterthemes) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=5.6.0->jupyterthemes) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=5.6.0->jupyterthemes) (21.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (1.6.7)\n",
      "Requirement already satisfied: psutil in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (5.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.18.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.4)\n",
      "Requirement already satisfied: webencodings in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zufhe\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYMEGomTjElk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTaNKpp1jER0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kvQptFIjFvE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
